{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1OHvBjZ3EiJgigTlRWDu2SVXhfoleL8Mc",
      "authorship_tag": "ABX9TyPB1XJeafpE4kKxLlgND2Bb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rvernica/notebook/blob/main/Deep_Neural_Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "N8pENN307uH2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "import scipy\n",
        "from PIL import Image\n",
        "from scipy import ndimage"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(Z):\n",
        "    \"\"\"\n",
        "    Implements the sigmoid activation in numpy\n",
        "\n",
        "    Arguments:\n",
        "    Z -- numpy array of any shape\n",
        "\n",
        "    Returns:\n",
        "    A -- output of sigmoid(z), same shape as Z\n",
        "    cache -- returns Z as well, useful during backpropagation\n",
        "    \"\"\"\n",
        "\n",
        "    A = 1/(1+np.exp(-Z))\n",
        "    cache = Z\n",
        "\n",
        "    return A, cache\n",
        "\n",
        "def relu(Z):\n",
        "    \"\"\"\n",
        "    Implement the RELU function.\n",
        "\n",
        "    Arguments:\n",
        "    Z -- Output of the linear layer, of any shape\n",
        "\n",
        "    Returns:\n",
        "    A -- Post-activation parameter, of the same shape as Z\n",
        "    cache -- a python dictionary containing \"A\" ; stored for computing the backward pass efficiently\n",
        "    \"\"\"\n",
        "\n",
        "    A = np.maximum(0,Z)\n",
        "\n",
        "    assert(A.shape == Z.shape)\n",
        "\n",
        "    cache = Z\n",
        "    return A, cache\n",
        "\n",
        "\n",
        "def relu_backward(dA, cache):\n",
        "    \"\"\"\n",
        "    Implement the backward propagation for a single RELU unit.\n",
        "\n",
        "    Arguments:\n",
        "    dA -- post-activation gradient, of any shape\n",
        "    cache -- 'Z' where we store for computing backward propagation efficiently\n",
        "\n",
        "    Returns:\n",
        "    dZ -- Gradient of the cost with respect to Z\n",
        "    \"\"\"\n",
        "\n",
        "    Z = cache\n",
        "    dZ = np.array(dA, copy=True) # just converting dz to a correct object.\n",
        "\n",
        "    # When z <= 0, you should set dz to 0 as well.\n",
        "    dZ[Z <= 0] = 0\n",
        "\n",
        "    assert (dZ.shape == Z.shape)\n",
        "\n",
        "    return dZ\n",
        "\n",
        "def sigmoid_backward(dA, cache):\n",
        "    \"\"\"\n",
        "    Implement the backward propagation for a single SIGMOID unit.\n",
        "\n",
        "    Arguments:\n",
        "    dA -- post-activation gradient, of any shape\n",
        "    cache -- 'Z' where we store for computing backward propagation efficiently\n",
        "\n",
        "    Returns:\n",
        "    dZ -- Gradient of the cost with respect to Z\n",
        "    \"\"\"\n",
        "\n",
        "    Z = cache\n",
        "\n",
        "    s = 1/(1+np.exp(-Z))\n",
        "    dZ = dA * s * (1-s)\n",
        "\n",
        "    assert (dZ.shape == Z.shape)\n",
        "\n",
        "    return dZ"
      ],
      "metadata": {
        "id": "4Msd6FsD77OE"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_parameters_deep(layer_dims):\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "    layer_dims -- python array (list) containing the dimensions of each layer in our network\n",
        "\n",
        "    Returns:\n",
        "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", ..., \"WL\", \"bL\":\n",
        "                    Wl -- weight matrix of shape (layer_dims[l], layer_dims[l-1])\n",
        "                    bl -- bias vector of shape (layer_dims[l], 1)\n",
        "    \"\"\"\n",
        "\n",
        "    np.random.seed(1)\n",
        "    parameters = {}\n",
        "    L = len(layer_dims)            # number of layers in the network\n",
        "\n",
        "    for l in range(1, L):\n",
        "        parameters['W' + str(l)] = np.random.randn(layer_dims[l], layer_dims[l-1]) / np.sqrt(layer_dims[l-1]) #*0.01\n",
        "        parameters['b' + str(l)] = np.zeros((layer_dims[l], 1))\n",
        "\n",
        "        assert(parameters['W' + str(l)].shape == (layer_dims[l], layer_dims[l-1]))\n",
        "        assert(parameters['b' + str(l)].shape == (layer_dims[l], 1))\n",
        "\n",
        "    return parameters"
      ],
      "metadata": {
        "id": "iKB1pvRY7796"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def linear_forward(A, W, b):\n",
        "    \"\"\"\n",
        "    Implement the linear part of a layer's forward propagation.\n",
        "\n",
        "    Arguments:\n",
        "    A -- activations from previous layer (or input data): (size of previous layer, number of examples)\n",
        "    W -- weights matrix: numpy array of shape (size of current layer, size of previous layer)\n",
        "    b -- bias vector, numpy array of shape (size of the current layer, 1)\n",
        "\n",
        "    Returns:\n",
        "    Z -- the input of the activation function, also called pre-activation parameter\n",
        "    cache -- a python tuple containing \"A\", \"W\" and \"b\" ; stored for computing the backward pass efficiently\n",
        "    \"\"\"\n",
        "\n",
        "    Z = W @ A + b\n",
        "\n",
        "    assert(Z.shape == (W.shape[0], A.shape[1]))\n",
        "    cache = (A, W, b)\n",
        "\n",
        "    return Z, cache"
      ],
      "metadata": {
        "id": "CZIr51Be8D1N"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def linear_activation_forward(A_prev, W, b, activation):\n",
        "    \"\"\"\n",
        "    Implement the forward propagation for the LINEAR->ACTIVATION layer\n",
        "\n",
        "    Arguments:\n",
        "    A_prev -- activations from previous layer (or input data): (size of previous layer, number of examples)\n",
        "    W -- weights matrix: numpy array of shape (size of current layer, size of previous layer)\n",
        "    b -- bias vector, numpy array of shape (size of the current layer, 1)\n",
        "    activation -- the activation to be used in this layer, stored as a text string: \"sigmoid\" or \"relu\"\n",
        "\n",
        "    Returns:\n",
        "    A -- the output of the activation function, also called the post-activation value\n",
        "    cache -- a python tuple containing \"linear_cache\" and \"activation_cache\";\n",
        "             stored for computing the backward pass efficiently\n",
        "    \"\"\"\n",
        "\n",
        "    if activation == \"sigmoid\":\n",
        "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
        "        A, activation_cache = sigmoid(Z)\n",
        "\n",
        "    elif activation == \"relu\":\n",
        "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
        "        A, activation_cache = relu(Z)\n",
        "\n",
        "    assert (A.shape == (W.shape[0], A_prev.shape[1]))\n",
        "    cache = (linear_cache, activation_cache)\n",
        "\n",
        "    return A, cache"
      ],
      "metadata": {
        "id": "qGWS5rOI8QzR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def L_model_forward(X, parameters):\n",
        "    \"\"\"\n",
        "    Implement forward propagation for the [LINEAR->RELU]*(L-1)->LINEAR->SIGMOID computation\n",
        "\n",
        "    Arguments:\n",
        "    X -- data, numpy array of shape (input size, number of examples)\n",
        "    parameters -- output of initialize_parameters_deep()\n",
        "\n",
        "    Returns:\n",
        "    AL -- activation value from the output (last) layer\n",
        "    caches -- list of caches containing:\n",
        "                every cache of linear_activation_forward() (there are L of them, indexed from 0 to L-1)\n",
        "    \"\"\"\n",
        "\n",
        "    caches = []\n",
        "    A = X\n",
        "    L = len(parameters) // 2                  # number of layers in the neural network\n",
        "\n",
        "    # Implement [LINEAR -> RELU]*(L-1). Add \"cache\" to the \"caches\" list.\n",
        "    # The for loop starts at 1 because layer 0 is the input\n",
        "    for l in range(1, L):\n",
        "        A_prev = A\n",
        "        A, cache = linear_activation_forward(A_prev, parameters[\"W\"+str(l)], parameters[\"b\"+str(l)], \"relu\")\n",
        "        caches.append(cache)\n",
        "\n",
        "    # Implement LINEAR -> SIGMOID. Add \"cache\" to the \"caches\" list.\n",
        "    AL, cache = linear_activation_forward(A, parameters[\"W\"+str(L)], parameters[\"b\"+str(L)], \"sigmoid\")\n",
        "    caches.append(cache)\n",
        "\n",
        "    assert(AL.shape == (1,X.shape[1]))\n",
        "    return AL, caches"
      ],
      "metadata": {
        "id": "yABWDtcx8Vku"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_cost(AL, Y):\n",
        "    \"\"\"\n",
        "    Implement the cost function defined by equation (7).\n",
        "\n",
        "    Arguments:\n",
        "    AL -- probability vector corresponding to your label predictions, shape (1, number of examples)\n",
        "    Y -- true \"label\" vector (for example: containing 0 if non-cat, 1 if cat), shape (1, number of examples)\n",
        "\n",
        "    Returns:\n",
        "    cost -- cross-entropy cost\n",
        "    \"\"\"\n",
        "\n",
        "    m = Y.shape[1]\n",
        "\n",
        "    # Compute loss from aL and y.\n",
        "    # cost = -1. / m * np.sum(Y * np.log(AL) + (1 - Y) * np.log(1 - AL))\n",
        "    cost = (1./m) * (-np.dot(Y,np.log(AL).T) - np.dot(1-Y, np.log(1-AL).T))\n",
        "\n",
        "    cost = np.squeeze(cost)      # To make sure your cost's shape is what we expect (e.g. this turns [[17]] into 17).\n",
        "    assert(cost.shape == ())\n",
        "    return cost"
      ],
      "metadata": {
        "id": "JlFJMQIp8gU7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def linear_backward(dZ, cache):\n",
        "    \"\"\"\n",
        "    Implement the linear portion of backward propagation for a single layer (layer l)\n",
        "\n",
        "    Arguments:\n",
        "    dZ -- Gradient of the cost with respect to the linear output (of current layer l)\n",
        "    cache -- tuple of values (A_prev, W, b) coming from the forward propagation in the current layer\n",
        "\n",
        "    Returns:\n",
        "    dA_prev -- Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev\n",
        "    dW -- Gradient of the cost with respect to W (current layer l), same shape as W\n",
        "    db -- Gradient of the cost with respect to b (current layer l), same shape as b\n",
        "    \"\"\"\n",
        "    A_prev, W, b = cache\n",
        "    m = A_prev.shape[1]\n",
        "\n",
        "    dW = 1. / m * dZ @ A_prev.T\n",
        "    db = 1. / m * np.sum(dZ, axis=1, keepdims=True)\n",
        "    dA_prev = W.T @ dZ\n",
        "\n",
        "    assert (dA_prev.shape == A_prev.shape)\n",
        "    assert (dW.shape == W.shape)\n",
        "    assert (db.shape == b.shape)\n",
        "\n",
        "    return dA_prev, dW, db"
      ],
      "metadata": {
        "id": "GQy0G8N58lBl"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def linear_activation_backward(dA, cache, activation):\n",
        "    \"\"\"\n",
        "    Implement the backward propagation for the LINEAR->ACTIVATION layer.\n",
        "\n",
        "    Arguments:\n",
        "    dA -- post-activation gradient for current layer l\n",
        "    cache -- tuple of values (linear_cache, activation_cache) we store for computing backward propagation efficiently\n",
        "    activation -- the activation to be used in this layer, stored as a text string: \"sigmoid\" or \"relu\"\n",
        "\n",
        "    Returns:\n",
        "    dA_prev -- Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev\n",
        "    dW -- Gradient of the cost with respect to W (current layer l), same shape as W\n",
        "    db -- Gradient of the cost with respect to b (current layer l), same shape as b\n",
        "    \"\"\"\n",
        "    linear_cache, activation_cache = cache\n",
        "\n",
        "    if activation == \"relu\":\n",
        "        dZ = relu_backward(dA, activation_cache)\n",
        "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
        "\n",
        "    elif activation == \"sigmoid\":\n",
        "        dZ = sigmoid_backward(dA, activation_cache)\n",
        "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
        "\n",
        "    return dA_prev, dW, db"
      ],
      "metadata": {
        "id": "R9JEcOjV8qSa"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def L_model_backward(AL, Y, caches):\n",
        "    \"\"\"\n",
        "    Implement the backward propagation for the [LINEAR->RELU] * (L-1) -> LINEAR -> SIGMOID group\n",
        "\n",
        "    Arguments:\n",
        "    AL -- probability vector, output of the forward propagation (L_model_forward())\n",
        "    Y -- true \"label\" vector (containing 0 if non-cat, 1 if cat)\n",
        "    caches -- list of caches containing:\n",
        "                every cache of linear_activation_forward() with \"relu\" (it's caches[l], for l in range(L-1) i.e l = 0...L-2)\n",
        "                the cache of linear_activation_forward() with \"sigmoid\" (it's caches[L-1])\n",
        "\n",
        "    Returns:\n",
        "    grads -- A dictionary with the gradients\n",
        "             grads[\"dA\" + str(l)] = ...\n",
        "             grads[\"dW\" + str(l)] = ...\n",
        "             grads[\"db\" + str(l)] = ...\n",
        "    \"\"\"\n",
        "    grads = {}\n",
        "    L = len(caches) # the number of layers\n",
        "    m = AL.shape[1]\n",
        "    Y = Y.reshape(AL.shape) # after this line, Y is the same shape as AL\n",
        "\n",
        "    # Initializing the backpropagation\n",
        "    dAL = - (np.divide(Y, AL) - np.divide(1 - Y, 1 - AL)) # derivative of cost with respect to AL\n",
        "\n",
        "    # YOUR CODE ENDS HERE\n",
        "\n",
        "    # Lth layer (SIGMOID -> LINEAR) gradients. Inputs: \"dAL, current_cache\". Outputs: \"grads[\"dAL-1\"], grads[\"dWL\"], grads[\"dbL\"]\n",
        "    current_cache = caches[L-1]\n",
        "    dA_prev_temp, dW_temp, db_temp = linear_activation_backward(dAL, current_cache, \"sigmoid\")\n",
        "    grads[\"dA\" + str(L - 1)] = dA_prev_temp\n",
        "    grads[\"dW\" + str(L)] = dW_temp\n",
        "    grads[\"db\" + str(L)] = db_temp\n",
        "\n",
        "    # Loop from l=L-2 to l=0\n",
        "    for l in reversed(range(L-1)):\n",
        "        # lth layer: (RELU -> LINEAR) gradients.\n",
        "        current_cache = caches[l]\n",
        "        dA_prev_temp, dW_temp, db_temp = linear_activation_backward(dA_prev_temp, current_cache, \"relu\")\n",
        "        grads[\"dA\" + str(l)] = dA_prev_temp\n",
        "        grads[\"dW\" + str(l + 1)] = dW_temp\n",
        "        grads[\"db\" + str(l + 1)] = db_temp\n",
        "\n",
        "    return grads"
      ],
      "metadata": {
        "id": "sQroFWeH8uyy"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def update_parameters(parameters, grads, learning_rate):\n",
        "    \"\"\"\n",
        "    Update parameters using gradient descent\n",
        "\n",
        "    Arguments:\n",
        "    params -- python dictionary containing your parameters\n",
        "    grads -- python dictionary containing your gradients, output of L_model_backward\n",
        "\n",
        "    Returns:\n",
        "    parameters -- python dictionary containing your updated parameters\n",
        "                  parameters[\"W\" + str(l)] = ...\n",
        "                  parameters[\"b\" + str(l)] = ...\n",
        "    \"\"\"\n",
        "    # parameters = copy.deepcopy(params)\n",
        "    L = len(parameters) // 2 # number of layers in the neural network\n",
        "\n",
        "    # Update rule for each parameter. Use a for loop.\n",
        "    #(â‰ˆ 2 lines of code)\n",
        "    for l in range(L):\n",
        "        parameters[\"W\" + str(l + 1)] -= learning_rate * grads[\"dW\" + str(l + 1)]\n",
        "        parameters[\"b\" + str(l + 1)] -= learning_rate * grads[\"db\" + str(l + 1)]\n",
        "\n",
        "    return parameters"
      ],
      "metadata": {
        "id": "KgrWG0QT828v"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data():\n",
        "    base_path = '/content/drive/MyDrive/Colab Notebooks/datasets/'\n",
        "    train_dataset = h5py.File(base_path + 'train_catvnoncat.h5', \"r\")\n",
        "    train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:]) # your train set features\n",
        "    train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:]) # your train set labels\n",
        "\n",
        "    test_dataset = h5py.File(base_path + 'test_catvnoncat.h5', \"r\")\n",
        "    test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:]) # your test set features\n",
        "    test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:]) # your test set labels\n",
        "\n",
        "    classes = np.array(test_dataset[\"list_classes\"][:]) # the list of classes\n",
        "\n",
        "    train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n",
        "    test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n",
        "\n",
        "    return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes"
      ],
      "metadata": {
        "id": "NHP9hhrnuem6"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x_orig, train_y, test_x_orig, test_y, classes = load_data()"
      ],
      "metadata": {
        "id": "FvIpKSJuurzs"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Explore your dataset\n",
        "m_train = train_x_orig.shape[0]\n",
        "num_px = train_x_orig.shape[1]\n",
        "m_test = test_x_orig.shape[0]\n",
        "\n",
        "print (\"Number of training examples: \" + str(m_train))\n",
        "print (\"Number of testing examples: \" + str(m_test))\n",
        "print (\"Each image is of size: (\" + str(num_px) + \", \" + str(num_px) + \", 3)\")\n",
        "print (\"train_x_orig shape: \" + str(train_x_orig.shape))\n",
        "print (\"train_y shape: \" + str(train_y.shape))\n",
        "print (\"test_x_orig shape: \" + str(test_x_orig.shape))\n",
        "print (\"test_y shape: \" + str(test_y.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khsSnzvV1LH2",
        "outputId": "0601bf88-af3e-4433-df12-591986779b47"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training examples: 209\n",
            "Number of testing examples: 50\n",
            "Each image is of size: (64, 64, 3)\n",
            "train_x_orig shape: (209, 64, 64, 3)\n",
            "train_y shape: (1, 209)\n",
            "test_x_orig shape: (50, 64, 64, 3)\n",
            "test_y shape: (1, 50)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index = 10\n",
        "plt.imshow(train_x_orig[index])\n",
        "print (\"y = \" + str(train_y[0,index]) + \". It's a \" + classes[train_y[0,index]].decode(\"utf-8\") +  \" picture.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "EU4hW3kduwF9",
        "outputId": "66112290-a455-44b1-9393-67706eb33e77"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y = 0. It's a non-cat picture.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape the training and test examples\n",
        "train_x_flatten = train_x_orig.reshape(train_x_orig.shape[0], -1).T   # The \"-1\" makes reshape flatten the remaining dimensions\n",
        "test_x_flatten = test_x_orig.reshape(test_x_orig.shape[0], -1).T\n",
        "\n",
        "# Standardize data to have feature values between 0 and 1.\n",
        "train_x = train_x_flatten/255.\n",
        "test_x = test_x_flatten/255.\n",
        "\n",
        "print (\"train_x's shape: \" + str(train_x.shape))\n",
        "print (\"test_x's shape: \" + str(test_x.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xljWisvpvNf8",
        "outputId": "d18e42a1-ffba-415f-8d0b-c573c51ea2b0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_x's shape: (12288, 209)\n",
            "test_x's shape: (12288, 50)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def L_layer_model(X, Y, layers_dims, learning_rate = 0.0075, num_iterations = 3000, print_cost=False):\n",
        "    \"\"\"\n",
        "    Implements a L-layer neural network: [LINEAR->RELU]*(L-1)->LINEAR->SIGMOID.\n",
        "\n",
        "    Arguments:\n",
        "    X -- input data, of shape (n_x, number of examples)\n",
        "    Y -- true \"label\" vector (containing 1 if cat, 0 if non-cat), of shape (1, number of examples)\n",
        "    layers_dims -- list containing the input size and each layer size, of length (number of layers + 1).\n",
        "    learning_rate -- learning rate of the gradient descent update rule\n",
        "    num_iterations -- number of iterations of the optimization loop\n",
        "    print_cost -- if True, it prints the cost every 100 steps\n",
        "\n",
        "    Returns:\n",
        "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
        "    \"\"\"\n",
        "\n",
        "    np.random.seed(1)\n",
        "    costs = []                         # keep track of cost\n",
        "\n",
        "    # Parameters initialization.\n",
        "    parameters = initialize_parameters_deep(layers_dims)\n",
        "\n",
        "    # Loop (gradient descent)\n",
        "    for i in range(0, num_iterations):\n",
        "\n",
        "        # Forward propagation: [LINEAR -> RELU]*(L-1) -> LINEAR -> SIGMOID.\n",
        "        AL, caches = L_model_forward(X, parameters)\n",
        "\n",
        "        # Compute cost.\n",
        "        cost = compute_cost(AL, Y)\n",
        "\n",
        "        # Backward propagation.\n",
        "        grads = L_model_backward(AL, Y, caches)\n",
        "\n",
        "        # Update parameters.\n",
        "        parameters = update_parameters(parameters, grads, learning_rate)\n",
        "\n",
        "        # Print the cost every 100 iterations and for the last iteration\n",
        "        if print_cost and (i % 100 == 0 or i == num_iterations - 1):\n",
        "            print(\"Cost after iteration {}: {}\".format(i, np.squeeze(cost)))\n",
        "        if i % 100 == 0:\n",
        "            costs.append(cost)\n",
        "\n",
        "    return parameters, costs"
      ],
      "metadata": {
        "id": "yRKiw0UIvRVp"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parameters, costs = L_layer_model(train_x, train_y, [12288, 20, 7, 5, 1], num_iterations = 1, print_cost = False)\n",
        "\n",
        "print(\"Cost after first iteration: \" + str(costs[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "raWRsiA-05vV",
        "outputId": "509b9133-2245-4dda-a728-aea6f37829b4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cost after first iteration: 0.7717493284237686\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parameters, costs = L_layer_model(train_x, train_y, [12288, 20, 7, 5, 1] , num_iterations = 2500, print_cost = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PlRnmXu9w2B7",
        "outputId": "c3938a59-b9c5-4eb7-d28d-1d9fdf3c73c6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cost after iteration 0: 0.7717493284237686\n",
            "Cost after iteration 100: 0.6720534400822914\n",
            "Cost after iteration 200: 0.6482632048575212\n",
            "Cost after iteration 300: 0.6115068816101356\n",
            "Cost after iteration 400: 0.5670473268366112\n",
            "Cost after iteration 500: 0.5401376634547801\n",
            "Cost after iteration 600: 0.5279299569455267\n",
            "Cost after iteration 700: 0.46547737717668514\n",
            "Cost after iteration 800: 0.36912585249592794\n",
            "Cost after iteration 900: 0.39174697434805356\n",
            "Cost after iteration 1000: 0.31518698886006175\n",
            "Cost after iteration 1100: 0.2726998441789385\n",
            "Cost after iteration 1200: 0.23741853400268137\n",
            "Cost after iteration 1300: 0.19960120532208644\n",
            "Cost after iteration 1400: 0.18926300388463305\n",
            "Cost after iteration 1500: 0.16118854665827753\n",
            "Cost after iteration 1600: 0.14821389662363316\n",
            "Cost after iteration 1700: 0.13777487812972944\n",
            "Cost after iteration 1800: 0.12974017549190123\n",
            "Cost after iteration 1900: 0.12122535068005211\n",
            "Cost after iteration 2000: 0.1138206066863371\n",
            "Cost after iteration 2100: 0.10783928526254132\n",
            "Cost after iteration 2200: 0.10285466069352679\n",
            "Cost after iteration 2300: 0.10089745445261786\n",
            "Cost after iteration 2400: 0.09287821526472397\n",
            "Cost after iteration 2499: 0.088439943441702\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(X, y, parameters):\n",
        "    \"\"\"\n",
        "    This function is used to predict the results of a  L-layer neural network.\n",
        "\n",
        "    Arguments:\n",
        "    X -- data set of examples you would like to label\n",
        "    parameters -- parameters of the trained model\n",
        "\n",
        "    Returns:\n",
        "    p -- predictions for the given dataset X\n",
        "    \"\"\"\n",
        "\n",
        "    m = X.shape[1]\n",
        "    n = len(parameters) // 2 # number of layers in the neural network\n",
        "    p = np.zeros((1,m))\n",
        "\n",
        "    # Forward propagation\n",
        "    probas, caches = L_model_forward(X, parameters)\n",
        "\n",
        "\n",
        "    # convert probas to 0/1 predictions\n",
        "    for i in range(0, probas.shape[1]):\n",
        "        if probas[0,i] > 0.5:\n",
        "            p[0,i] = 1\n",
        "        else:\n",
        "            p[0,i] = 0\n",
        "\n",
        "    #print results\n",
        "    #print (\"predictions: \" + str(p))\n",
        "    #print (\"true labels: \" + str(y))\n",
        "    print(\"Accuracy: \"  + str(np.sum((p == y)/m)))\n",
        "\n",
        "    return p"
      ],
      "metadata": {
        "id": "PaHL7LAByMj1"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_train = predict(train_x, train_y, parameters)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SxRjmsrw4c1",
        "outputId": "0360c063-45d5-454a-ecf6-cd01d6baaf79"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9856459330143539\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_test = predict(test_x, test_y, parameters)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_wSvm25yNes",
        "outputId": "f37a696f-7507-451f-d48c-adca3b3433a5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8\n"
          ]
        }
      ]
    }
  ]
}